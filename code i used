import sklearn.datasets
import sklearn.linear_model
import sklearn.tree
import sklearn.ensemble
import sklearn.model_selection
import sklearn.metrics
import numpy as np

import matplotlib.pyplot as plt 
%matplotlib inline

olivetti_faces = sklearn.datasets.fetch_olivetti_faces(random_state=0,)
print(olivetti_faces['DESCR'])

example_indices = [0, 10, 62, 70]
for idx in example_indices:
    plt.title(olivetti_faces['target'][idx])
    plt.imshow(olivetti_faces['images'][idx])
    plt.gray()
    plt.show()
    
X = olivetti_faces['data']
y = olivetti_faces['target']
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.3, random_state=0)

TODO

#1. Create a classification object in scikit learn package (such as perceptron, logistic regression, or other classification algorithms)
log_reg = sklearn.linear_model.LogisticRegression(tol=0.01, C=10.0,max_iter=10000)

#2. Fit the object to training dataset
log_reg.fit(X_train, y_train,)
#3. Predict the label of test data point (X_test)
y_pred = log_reg.predict(X_test)

print('Accuracy: %.5f' % sklearn.metrics.accuracy_score(y_test, y_pred))
